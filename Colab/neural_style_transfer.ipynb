{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_style_transfer.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vaL0Z5kFkfTK","colab_type":"text"},"cell_type":"markdown","source":["# Neural Style Transfer with **Keras**\n","\n","Hello !\n","\n","This is a python script to perfom Neural Style Transfer, which consists into applying the style of a \"style image\" to a \"content image\", giving pretty results.\n","\n","I'm using Keras with a Tensorflow backend. Neural Style Transfer is an application of Deep Learning and so is computer intensive, that's why I have ported it to Google Collab in order to run it on its online GPU.\n","\n","Follow my instructions to run this code and try it for yourself !\n","\n","**The setup : **\n","\n","You must have :\n","\n","* **This script**.\n","*  **neural_style_transfer.py**, it's the file with the important functions.\n","*  An **images.zip** archives, with the images you want to use, in the file and folder hierarchy that you want, as long as you know it. We use a zip instead of a folder because it's faster to upload.\n","\n","You will be able to upload these files to Colab either through Google Drive, or from your PC.\n","\n"]},{"metadata":{"id":"jRI0_SRWlvS_","colab_type":"text"},"cell_type":"markdown","source":["First, run the below cell to connect to Google Colab, open a session, import useful packages, and be able to import file froms Google Drive. \n","\n","It will ask you to open a browser link twice to get a key to authentificate yourself, that you'll have to copy in an input bar."]},{"metadata":{"id":"2Kqtgs07g1KE","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#Install basic libraries + authorizations\n","\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","#Libraries and imports to use Google Drive and Google SDK\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","import os\n","import pandas as pd\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xtVR7Krc39zm","colab_type":"text"},"cell_type":"markdown","source":["# **UPLOAD THE FILES**"]},{"metadata":{"id":"WKmLmegvngyK","colab_type":"text"},"cell_type":"markdown","source":["### 1 - with Google Drive\n","\n","In order to access your Google Drive files and upload them to Colab (Colab has its own working directory that's is NOT the current drive folder !) you'll have to know their files ID.\n","\n","To find their ID, you can run this cell, if will show you the id of each files and folders in your root Google Drive directory. If those files are not into your root Directory, just replace 'root' by the ID of the folder they are in, and repeat the processus until you find the files.\n","\n","Once found, write those id as variable in the next cell.\n"]},{"metadata":{"id":"vxaFTHr2hjRI","colab_type":"code","colab":{}},"cell_type":"code","source":["#Search for files ID.\n","\n","file_list = drive.ListFile({'q': \"'1MO0Ul6kfHaBbAnKp-rzjP93PjFVarIFM' in parents and trashed=false\"}).GetList()\n","for file1 in file_list:\n","  print('title: %s, id: %s' % (file1['title'], file1['id']))\n","  \n","#1u1I9XFVV1J6tMVY2JaL5aDYbWd_yW3kg DeepLearning Folder ID\n","  #1YqussFrEICOCX7g58IQBGawkFoO6nwFj CNN Folder ID\n","    #178iucUFvfTcS1Vdq5FmmF5EbSZFTK0cF dataset.zip ID\n","  #1Wzyoh4BQk8pLohHkJDKoAd7qQVGbE4JD ANN Folder ID\n","  \n","  #1MO0Ul6kfHaBbAnKp-rzjP93PjFVarIFM NST Folder ID\n","    #1or9DvsalgQkJyyzYJ5RuZBAuO9HfBlly Neural_style_transfer.ipnyb #this\n","    #1kOOTgh4bNak5CxUBiH2txcTw-TaUqvgp images.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jvy3uS3Povnl","colab_type":"text"},"cell_type":"markdown","source":["Now that we know their ID, we can upload those files."]},{"metadata":{"id":"RKZmsq2Rnu5-","colab_type":"code","colab":{}},"cell_type":"code","source":["#Complete/replace with your files ID.\n","image_zip_id = '1kOOTgh4bNak5CxUBiH2txcTw-TaUqvgp';\n","nst_py_id = '1YLoXGN2M7h5dm1oqo7JYNm3p5HxFf6_7';\n","\n","### Upload the images \n","\n","#Download images from Drive to Colab's working directory.\n","download = drive.CreateFile({'id': image_zip_id})\n","download.GetContentFile('images.zip')\n","\n","#Unzip the images folder in the Colab local directory, remember your folder hierarchy !\n","!unzip -o images.zip > /dev/null #Hide output\n","\n","#Display Colab working directory, you are supposed to see\n","# 'datalab', 'images', 'images.zip', 'neural_style_transfer.py'\n","\n","### Upload the script and import it as a module.\n","download = drive.CreateFile({'id': nst_py_id})\n","download.GetContentFile('neural_style_transfer.py')\n","#from google.colab import files\n","#src = list(files.upload().values())[0]\n","#open('neural_style_transfer.py','wb').write(src)\n","from neural_style_transfer import style_transfer\n","\n","!ls\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JJWBU72B4OjU","colab_type":"text"},"cell_type":"markdown","source":["### 2 - Upload from your PC\n","\n","Just run the code below, it will open the file explorer and you'll just need to select your two files.\n","It's way more simple than Google Drive, but uploading takes more time, especially if you have a lot of images."]},{"metadata":{"id":"ASK53ciO2ZxN","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files\n","src = list(files.upload().values())[0]\n","\n","!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GYydbfDzsWy8","colab_type":"text"},"cell_type":"markdown","source":["Now that those files are uploaded, we can unzip the zip with the images files and import the python script as a module wit the code below."]},{"metadata":{"id":"GzqoyaOesT3F","colab_type":"code","colab":{}},"cell_type":"code","source":["#Unzip the images folder in the Colab local directory, remember your folder hierarchy !\n","!unzip -o images.zip > /dev/null #Hide output\n","\n","!ls\n","#Display Colab's current working directory, you are supposed to see\n","#'images', 'images.zip', 'neural_style_transfer.py', and some additional unrelated stuff\n","\n","#Import the magical function from our script.\n","from neural_style_transfer import style_transfer\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nTJwfsJtrAC3","colab_type":"text"},"cell_type":"markdown","source":["# **Now you can try it out yourself !**\n","\n","You completed the most annoying part ! Now, you can adjust all the different possible parameters in the below cell, then launch the transformation with the next cell !\n","\n","A rundown of all the parameters :\n","\n","### IMAGES PATH\n","The name of the images used for your transformation\n","* **content_img_name** : The content image name\n","* **style_img_name** : The style image name\n","* **output_img_name** : The name of the output image\n","\n","#### Full paths\n","* **style_image_path**\n","* **content_image_path**\n","* **output_image_path**\n","\n","Complete those with the directory path of where you can find those images . (That's why you need to remember the hierarchy of your images folder)\n","\n","\n","### DIMENSIONS\n","To control the size of your output image. The bigger it is, the more time it takes to compute.\n","* **loadDims** : If set to True, use the native dimensions of the content image, else, it will resize with the width and height parameters values.\n","* **width** and **height** : Dimensions to which resize the image if loadDims is set to False.\n","* **rescale** : If loadDims is set to True, will resize the image by this factor.\n","* **max_size** : If loadDims is set to True, while automatically resize the image to below this value if it has more pixels than max_size. Set to -1 to ignore.\n","\n","### MISC\n","\n","* **withBaseImage** : If True, will use the content image as the starting image when starting the transformation. Set to False to start from random noises. I recommend True as I hardly had any convincing results with noises.\n","* **stepsBeforeSaveAndShow** : The number of iterations before it save and show the current generated image, for example if set to 3, will display the current output image and save it every 3 iterations.\n","* **nb_iterations** : Total number of iterations, I recommend between 20-50. Below is not always reliable and above hardly shows any improvements. \n","\n","### LOSSES WEIGHTS\n","Related to the calculation for the algorithms. It tells how much the generated image needs to be close to the content and style images in term of content and style. \n","\n","Usually, content_weight is very very low compared to the style_weight. \n","The variation weight is used to have more smooth looking pictures, there's barely any needs to modify it from it default value.\n","* **content_weight** : 0.025 as default value.\n","* **style_weight** : 5.0 as default value.\n","* **var_weight** : 1.0 as default value.\n","\n","### LAYERS USED FOR LOSSES CALCULATIONS\n","Also related to the loss calculation. I won't go into the Math, but this algorithm put the images into a pre-trained Convolutional Neural Network (VGG16 in our case, it's quite efficient), and retrieve the outputs on some of its layers to perform calculation and tell how close our generated image is close to the wanted result :\n","\n","Content loss tells how much the generated image is close to the content image in term of content, and usually only use the output of a single layer, one of the latest of the neural network.\n","\n","Style loss tells how much the generated image is close to the style image in term of style, and usually only use several layers outputs, often the first one from each \"block\" of convolutional layers. \n","\n","Those values are the list of the names of the layers used for each of those calculations. You need to know the layers name to modify it properly\n","* **ln_content**\n","* **ln_style**\n","\n"]},{"metadata":{"id":"OA6LTtekrcAl","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","### IMAGES PATH\n","\n","#Name of the images used for the style transfer.\n","content_img_name = \"sunflower.jpg\"\n","style_img_name = \"stained_glass_1.jpg\"\n","output_img_name = \"glass_sunflower.jpg\"\n","\n","#Full path of the image used, complete with your image folder path\n","style_image_path = \"./images/\" + style_img_name\n","content_image_path =  \"./images/\" + content_img_name\n","output_image_path = \"./output/\" + output_img_name\n","\n","\n","### DIMENSIONS\n","#Dimensions of the output image. Ignore is loadDims is set to True.\n","width = 500;\n","height = 500;\n","#True if you want to use native content image dims.\n","loadDims = True; \n","#Value by which rescaling the image, used only if LoadDims is set to True.\n","rescale = 1.0\n","#Scale the image down if height*width > max_size, keeps the image size ratio, set to -1 to ignore.\n","#Used only with LoadDims = true.\n","max_size = 250*250\n","\n","### VAR\n","\n","#True if starting from content image, False for random noise as starting image.\n","#Recommended to leave it on True, I haven't been able to have good results with random noises.\n","withBaseImage = True; \n","#Number of iterations before saving and showing the current generated image, -1 to ignore.\n","stepsBeforeSaveAndShow = 3\n","#Number of iterations on which calculating losses and modifying the base image. \n","#20-50 are the recommended numbers for good results\n","nb_iterations = 20\n","\n","### WEIGHTS : Importance of each kind of losses. \n","#default values : content = 0.025, style = 5.0, var_w = 1.0\n","content_weight = 0.025\n","style_weight = 5.0\n","var_weight = 1.\n","\n","### Layer used for the Loss calculations\n","ln_content = [\"block5_conv2\"]\n","ln_style = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \"block5_conv1\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EPdolwREzWU_","colab_type":"text"},"cell_type":"markdown","source":["Now run the next cell to start the transformation !"]},{"metadata":{"id":"y44Coi2VmUPs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4667,"output_embedded_package_id":"1c7azfaDqvD-2vDoUIPDDjGhNB-6fm5nx"},"outputId":"4db3c602-7bc6-4681-d7df-e7395085469a","executionInfo":{"status":"ok","timestamp":1534409073709,"user_tz":-480,"elapsed":97504,"user":{"displayName":"CawotteKiller","photoUrl":"//lh5.googleusercontent.com/-IxvREmnb84Q/AAAAAAAAAAI/AAAAAAAAACA/UM5atYFkXCw/s50-c-k-no/photo.jpg","userId":"104701040017335299781"}}},"cell_type":"code","source":["style_transfer(\n","        content_image_path, #Path of the content image\n","        style_image_path, #Path of the style image\n","        output_image_path, #Path of the output image\n","        loadDims, #True if using native image dim\n","        withBaseImage, #True if using content image as starting image, false for random noises.\n","        rescale, #Rescale the image, only useful if loadDims = true\n","        max_size, #Automatically rescale if height*width > max_size. -1 to ignore.\n","        height, #wanted height of the images, useless if loadDims.\n","        width, #wanted width of the images, useless if loadDims.\n","        nb_iterations, #number of iterations\n","        stepsBeforeSaveAndShow, \n","        content_weight,\n","        style_weight,\n","        var_weight,\n","        ln_content, #Layers used for loss content calculation\n","        ln_style #Layers used for style content calculation.\n","        )\n"],"execution_count":33},{"metadata":{"id":"BRE1ca5y6Niv","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kf_B04Rp0c9Y","colab_type":"text"},"cell_type":"markdown","source":["You can download your output image by running the code cell below !\n","\n","You can also download a previously generated image by changing \"output_image_path\" by the path of that image in the Colab directory."]},{"metadata":{"id":"RMpU2STl1-2T","colab_type":"code","colab":{}},"cell_type":"code","source":["#Download the output image to your PC.\n","from google.colab import files\n","files.download(output_image_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k-7PBlsp0nHV","colab_type":"text"},"cell_type":"markdown","source":["**WARNING**\n","\n","The next cell's code is used to reset the session, by killing it. I got sometimes bug when I tried to re-upload an image folder when I wanted to add new images, so I used it to just restart the whole session from the beginnin. You'll have to authentificate again."]},{"metadata":{"id":"IQRwmSqcMWPh","colab_type":"code","colab":{}},"cell_type":"code","source":["#COMPLETELY KILL AND RESET THE SESSION\n","#Sometime there's bug when you try to re-upload your images.zip in the same session (to add new images), \n","#You can use it to totally reset the session, you'll have to authentificate again !\n","!kill -9 -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mhc0K1zS1InG","colab_type":"code","colab":{}},"cell_type":"code","source":["#Clean the working directory, delete all images file, folder and zip. \n","#Useful if you want to delete previous images or changed your files hierarchy.\n","!rm -r images\n","!rm images.zip\n","\n","!ls"],"execution_count":0,"outputs":[]}]}